{
  "hash": "68705e6b2f5a1cba0b98464ae14b7ee6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In-class Exercise 06\"\nauthor: \"Thet Myat Noe\"\ndate: \"May 18, 2024\"\ndate-modified: \"last-modified\"\nexecute:\n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n# Importing JSON MC3\n## 1. Loading R Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(jsonlite,tidyverse,tidyr)\n```\n:::\n\n\n## 2. Importing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_data <- fromJSON(\"data/MC3/mc3-v1.json\")\n```\n:::\n\n\n# Text Analytics\n## 1. Loading R Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(corporaexplorer,rvest,stringi)\n```\n:::\n\n\n## 2. Importing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbible <- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n```\n:::\n\n\n## 3. Pre-processing the text\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Collapsing into one string.\nbible <- paste(bible, collapse = \"\\n\")\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v <- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v <- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible <- stri_sub(bible, start_v, end_v)\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks <- stri_split_regex(bible, \"\\n{5}\") %>%\n    unlist %>%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks <- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %>%\n    str_replace_all(\"\\n\", \" \") %>%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks <- books[3:68]  # The two first elements are not books\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters <- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %>%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters <- lapply(chapters, function(x) x[-1])\n```\n:::\n\n\n## 4. Metadata\nWe are not quite happy with the long book titles in the King James Bible, so we retrieve shorter versions from esv.org which will take up less space in the corpus map plot.\n\n::: {.cell}\n\n```{.r .cell-code}\nbook_titles <- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %>%\n  html_nodes(\"td:nth-child(1)\") %>%\n  html_text() %>%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n```\n:::\n\n\nWe add a column indicating whether a book belongs to the Old or New Testament, knowing that they contain respectively 39 and 27 books.\n\n::: {.cell}\n\n```{.r .cell-code}\ntestament <- c(rep(\"Old\", 39), rep(\"New\", 27))\n```\n:::\n\n\n## 5. Creating data frame with text and metadata\nData frame with one book as one row.\n\n::: {.cell}\n\n```{.r .cell-code}\nbible_df <- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df <- tidyr::unnest(bible_df, Text)\n```\n:::\n\n\n\n## 6. corporaexplorer\n\n::: {.cell}\n\n```{.r .cell-code}\nKJB <- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(KJB)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"corporaexplorerobject\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexplore(KJB)\n```\n\n::: {.cell-output-display}\n`<div style=\"width: 100% ; height: 400px ; text-align: center; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box;\" class=\"muted well\">Shiny applications not supported in static R Markdown documents</div>`{=html}\n:::\n:::\n\n\n# Network Analytics\n## 1. Loading R Packages\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(jsonlite,tidygraph, ggraph, visNetwork, graphlayouts, ggforce, skimr, tidytext, tidyverse,tidyr)\n```\n:::\n\n## 2. Importing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Vast Challenge 2023 MC3\nmc3_data_2023 <- fromJSON(\"data/MC3.json\")\n```\n:::\n\n\n## 3. Extract Edges\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_edges <-\nas_tibble(mc3_data_2023$links) %>%\n  distinct() %>%\n  mutate(source =\nas.character(source),\n         target =\nas.character(target),\n         type = as.character(type))%>%\n  group_by(source,target,type) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  ungroup()\n```\n:::\n\n\n## 4. Extract Nodes\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_nodes <-\nas_tibble(mc3_data_2023$nodes) %>%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = \n           as.character(product_services),\n         revenue_omu = \n           as.numeric(as.character(revenue_omu)),\n         type=as.character(type)) %>%\n  select(id,country,type,revenue_omu,product_services)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nid1 <- mc3_edges %>%\n  select(source) %>%\n  rename(id = source)\nid2 <- mc3_edges %>%\n  select(target) %>%\n  rename(id = target)\nmc3_nodes1 <- rbind(id1, id2) %>%\n  distinct() %>%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n```\n:::\n\n\n## 5. Construct the graph\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>%\n  mutate(betweenness_centrality =\n           centrality_betweenness(),\n         cloesness_centrality = centrality_closeness())\n```\n:::\n\n\n## 6. Plotting the network graph\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_graph %>%\n  filter(betweenness_centrality >= 100000) %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size= betweenness_centrality,\n    color = \"lightblue\",\n    alpha = 0.5))+\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()\n```\n\n::: {.cell-output-display}\n![](In-class_Ex06_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::",
    "supporting": [
      "In-class_Ex06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}