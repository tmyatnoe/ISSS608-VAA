{
  "hash": "12aaf3b15311048e5376fd313ffa4e4d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take-home Exercise 3\"\nauthor: \"Thet Myat Noe\"\ndate: \"May 14, 2024\"\ndate-modified: \"last-modified\"\ncode-fold: true\nexecute:\n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n![](fishing.gif){width=\"800\" height=\"500\"} source: Dribble.com\n\n# 1. Overview\n\n## 1.1 Setting the scene\n\nVast Challenge also known as IEEE Visual Analytics Science and Technology (VAST) Challenge is Visual Analytics competition which aims to promote innovation in the field of data transformation and interactive visualization. [Vast Challenge 2024](https://vast-challenge.github.io/2024/index.html) is based on the theme of detecting bias, illegal fishing behavior and temporal patterns in fishing industry in Oceanus, an island nation.\n\n## 1.2 Task\n\nThis exercise will be based on Mini-Challenge 2: [MC2](https://vast-challenge.github.io/2024/MC2.html) of Vast Challenge 2024. The objective of the exercise is to help FishEye, a non-profit organization to detect and prevent illegal fishing behaviour, by performing geographic and temporal visual analysis. This exercise will aim to answer the following questions from MC2 of Vast Challenge through visual analytics:\n\n**Question 1:**\n\n::: {style=\"border: 2px dotted black; background-color: #e6e6fa; padding: 15px; margin: 10px 0; border-radius: 5px; display: flex; align-items: center;\"}\n<img src=\"fish_1826379.png\" alt=\"Icon\" style=\"width: 48px; height: 48px; margin-right: 10px;\"/> Develop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. FishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?.\n:::\n\n**Question 2:**\n\n::: {style=\"border: 2px dotted black; background-color: #e6e6fa; padding: 15px; margin: 10px 0; border-radius: 5px; display: flex; align-items: center;\"}\n<img src=\"shark_1826583.png\" alt=\"Icon\" style=\"width: 48px; height: 48px; margin-right: 10px;\"/> Develop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.\n:::\n\n# 2. Getting Started\n\n## 2.1 Installing and loading the required libraries\n\nThe code chunk below uses `p_load()` function from **pacman** package to check if packages listed are already installed in the computer. The packages are loaded if they are found to be installed. If they are not installed, the function will proceed to install and load them into R environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(jsonlite,tidyverse,igraph,ggraph,RColorBrewer,sf)\n```\n:::\n\n\n## 2.2 Importing Data\n\nBelow code import MC2 data using fromJSON command from jsonlite package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_data <- fromJSON(\"data/MC2/mc2.json\")\n```\n:::\n\n\n### 2.2.1 Processing Edges/Links Data\n\nBelow code process and clean Edges data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load edges data to mc2_edges\nmc2_edges <- as_tibble(mc2_data$links) %>% \n  distinct() \n\n# Correcting date data type using lubridate package\nmc2_edges$time <- as_datetime(mc2_edges$time)\nmc2_edges$\"_last_edited_date\" <- as_datetime(mc2_edges$\"_last_edited_date\")\nmc2_edges$\"_date_added\" <- as_datetime(mc2_edges$\"_date_added\")\nmc2_edges$date <- as.POSIXct(mc2_edges$date, format = \"%Y-%m-%d\")\n\n# Updating field names\nmc2_edges <- mc2_edges %>%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\")\n\n# Divide different events into different table\nE_TransponderPing <- subset(mc2_edges,  mc2_edges$type == \"Event.TransportEvent.TransponderPing\")\nE_HarborRpt <- subset(mc2_edges,  mc2_edges$type == \"Event.HarborReport\")\nE_Tx <- subset(mc2_edges, mc2_edges$type == \"Event.Transaction\")\n\n# save mc2_edges into R rds file format\nwrite_rds(mc2_edges, \"data/rds/mc2_edges.rds\")\n```\n:::\n\n\nTake a look at mc2_edges to ensure data is processed correctly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(mc2_edges)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 271,643\nColumns: 17\n$ type                <chr> \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                <dttm> 2035-09-16 04:06:48, 2035-09-20 05:21:33, 2035-09…\n$ dwell               <dbl> 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ last_edited_by      <chr> \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ date_added          <dttm> 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-09…\n$ last_edited_date    <dttm> 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-10…\n$ raw_source          <chr> \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ algorithm           <chr> \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              <chr> \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              <chr> \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ data_author         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n```\n\n\n:::\n:::\n\n\n### 2.2.2 Processing Nodes Data\n\nBelow code process and clean Nodes data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load nodes data to mc2_nodes\nmc2_nodes <- as_tibble(mc2_data$nodes) %>%\n  distinct()\n\n# Correcting date data type using lubridate package\nmc2_nodes$\"_last_edited_date\" <- as_datetime(mc2_nodes$\"_last_edited_date\")\nmc2_nodes$\"_date_added\" <- as_datetime(mc2_nodes$\"_date_added\")\nmc2_nodes$date <- as.POSIXct(mc2_nodes$date, format = \"%Y-%m-%d\")\n\n# Updating field names\nmc2_nodes <- mc2_nodes %>%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\")\n\nmc2_nodes <- mc2_nodes %>%\n  mutate(Activities = gsub(\"c[(]\", \"\", Activities)) %>% \n  mutate(Activities = gsub(\"\\\"\", \"\", Activities)) %>%\n  mutate(Activities = gsub(\"[)]\", \"\", Activities)) \n\nmc2_nodes <- mc2_nodes %>%\n  mutate(fish_species_present = gsub(\"c[(]\", \"\", fish_species_present)) %>% \n  mutate(fish_species_present = gsub(\"\\\"\", \"\", fish_species_present)) %>%\n  mutate(fish_species_present = gsub(\"[)]\", \"\", fish_species_present)) \n\n# Divide different nodes into different table\nN_fish <- subset(mc2_nodes,  mc2_nodes$type == \"Entity.Commodity.Fish\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  select(-c(`type`, `raw_source`, `algorithm`, `Activities`, `fish_species_present`)) %>%\n  rename(fish_species = name, \n         fish_id = id)\n\nNL_City <- subset(mc2_nodes,  mc2_nodes$type == \"Entity.Location.City\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  select(-c(`raw_source`, `algorithm`, `type`, `fish_species_present`)) %>%\n  rename(city_name = Name, \n         city_id = id)\n\n\nNL_Point <- subset(mc2_nodes,  mc2_nodes$type == \"Entity.Location.Point\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  select(-c(`raw_source`, `algorithm`, `kind`, `fish_species_present`)) %>%\n  rename(point_name = Name, \n         point_id = id)\n\n# Need to tidy NL Region\nNL_Region <- subset(mc2_nodes,  mc2_nodes$type == \"Entity.Location.Region\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  select(-c(`raw_source`, `algorithm`, `type`, `Description`)) %>%\n  rename(region_name = Name, \n         region_id = id, \n         region_kind = kind)\n\nN_Delivery_doc <- subset(mc2_nodes,  mc2_nodes$type == \"Entity.Document.DeliveryReport\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  rename(deliver_date = date,\n         cargo_id = id) %>%\n  select(-c(`algorithm`, `type`, `raw_source`, `Activities`, `fish_species_present`)) \n\nN_vessel <- mc2_nodes %>%\n  filter(grepl(\"Entity.Vessel\", type)) %>%\n  mutate(vessel_type = case_when(\n    grepl(\"FishingVessel\", type, ignore.case = TRUE) ~ \"Fishing\",\n    grepl(\"Ferry.Passenger\", type, ignore.case = TRUE) ~ \"Ferry_Passenger\",\n    grepl(\"Ferry.Cargo\", type, ignore.case = TRUE) ~ \"Ferry_Cargo\",\n    grepl(\"Research\", type, ignore.case = TRUE) ~ \"Research\", \n    grepl(\"Other\", type, ignore.case = TRUE) ~ \"Other\", \n    grepl(\"Tour\", type, ignore.case = TRUE) ~ \"Tour\", \n    grepl(\"CargoVessel\", type, ignore.case = TRUE) ~ \"Cargo_Vessel\"\n    )) %>%\n  select(-c(`algorithm`, `type`, `raw_source`, `Activities`, `fish_species_present`)) %>%\n  mutate(company = ifelse(is.na(company), \"Unknown\", company)) %>% # Handle NA values by replacing NA with unknown\n  rename(vessel_id = id, \n         vessel_name = Name,\n         vessel_company = company) %>%\n  select_if(~ !any(is.na(.)))\n\n# save mc2_nodes into R rds file format\nwrite_rds(mc2_nodes, \"data/rds/mc2_nodes.rds\")\n```\n:::\n\n\nTake a look at mc2_nodes to ensure data is processed correctly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(mc2_nodes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 5,637\nColumns: 20\n$ type                 <chr> \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ last_edited_by       <chr> \"Clepper Jessen\", \"Clepper Jessen\", \"Haenyeo Hyun…\n$ date_added           <dttm> 2033-09-04, 2034-01-21, 2033-06-22, 2033-11-24, …\n$ last_edited_date     <dttm> 2035-01-25, 2035-01-04, 2035-01-14, 2035-01-14, …\n$ raw_source           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Oceanus:…\n$ algorithm            <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ name                 <chr> \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ id                   <chr> \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ Name                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Haacklee…\n$ Description          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           <chr> \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"…\n$ kind                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n$ qty_tons             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ date                 <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ flag_country         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ company              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ tonnage              <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ style                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present <chr> \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"NULL\", \"…\n```\n\n\n:::\n:::\n\n\n### 2.2.3 Processing Transponder Ping Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rename target column as vessel_id\nE_TransponderPing <- E_TransponderPing %>%\n  rename(vessel_id = target)\n\n# Join data tables to include vessel_type, vessel_company in transponder ping data and filter only Fishing vessel type\nE_Tping_Fishing <- E_TransponderPing %>%\n  left_join(N_vessel %>% select(vessel_id, vessel_type, vessel_company), by = \"vessel_id\") %>%\n  filter(vessel_type == \"Fishing\")\n```\n:::\n\n\n### 2.2.4 Oceanus Geographical Data Processing\nCode chunk below uses st_read() of sf package to import Oceanus Geography and Oceanus Locations geographical file in geojson format into R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# import into R\nOceanusGeography = st_read(\"data/MC2/OceanusGeography.geojson\") %>%\n  st_transform(crs = 4326)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OceanusGeography' from data source \n  `C:\\tmyatnoe\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex03\\data\\MC2\\OceanusGeography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n#save OceanusGeography into rds format for future use\nwrite_rds(OceanusGeography, \"data/rds/OceanusGeography.rds\")\n\n# import into R\nOceanusLocations <- st_read(dsn = \"data/shp\",\n  layer = \"Oceanus Geography\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Oceanus Geography' from data source \n  `C:\\tmyatnoe\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex03\\data\\shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 27 features and 7 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n#save OceanusGeography into rds format for future use\nwrite_rds(OceanusLocations, \"data/rds/OceanusLocations.rds\")\n```\n:::\n\n# 3. Visualisation\n\n## 3.1 Visualisations for Question 1\n\n### 3.1.1 Delivery Content (Fish Species)\n\nFirst, we need to associate Cargo in delivery doc to fish species info using Transaction and Fish Nodes data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract Cargo to Fish data from Transaction Event data\nCargo_to_Fish <- E_Tx %>%\n  filter(target %in% N_fish$fish_id) %>% select(source, target)\n\n# Match Cargo Id in delivery doc to fish Id from Transaction data\nN_Delivery_doc <- N_Delivery_doc %>%\n  left_join(Cargo_to_Fish, by = c(\"cargo_id\" = \"source\"))\n\n# Match Fish Id in delivery doc to fish species from Fish Nodes\nN_Delivery_doc <- N_Delivery_doc %>%\n  left_join(N_fish %>% select(\"fish_id\", \"fish_species\"), by = c(\"target\" = \"fish_id\"))\n\n# Rename Target Column in N_Delivery_doc to Fish Id\nN_Delivery_doc <- N_Delivery_doc %>% \n  rename(fish_id = target)\n```\n:::\n\n\nNext, extract date only from time column of transponder data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract Date only from time column of Transponder Ping data\nE_Tping_Fishing <- E_Tping_Fishing %>%\n  mutate(date_only = as.Date(time))\n```\n:::\n\n\nConnect possible cargo to vessels using date as connection.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Merge the datasets based on the date\nTping_to_Delivery <- E_Tping_Fishing %>%\n  filter(source %in% NL_City$city_id) %>%\n  left_join(N_Delivery_doc %>% select(\"deliver_date\",\"cargo_id\", \"qty_tons\", \"fish_id\", \"fish_species\"), by = c(\"date_only\" = \"deliver_date\"))\n```\n:::\n\n\nVisualize which company possibly delivers which fish species.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove duplicate rows based on vessel_company and fish_species\ndistinct_species <- Tping_to_Delivery %>%\n  distinct(vessel_company, fish_species) %>% na.omit() %>% select(vessel_company, fish_species)\n\n# Filter to show only the first 50 companies alphabetically\ncompanies1 <- distinct_species %>%\n  distinct(vessel_company) %>%\n  arrange(vessel_company) %>%\n  head(50) %>%\n  pull(vessel_company)\n\n# Filter the main dataframe to include only these companies\ncompanies1_data <- distinct_species %>%\n  filter(vessel_company %in% companies1)\n\n# Creating stacked bar chart\np1 <- ggplot(companies1_data, aes(x = vessel_company, fill = fish_species)) +\n  geom_bar(position = \"stack\") +\n  labs(title = \"Probable Fish Species Delivered by Company\",\n       x = \"Vessel Company\",\n       y = \"Fish Species\") +\n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_text(size = 8),\n        legend.text = element_text(size = 8),\n        legend.title = element_text(size = 8)) +\n  scale_fill_discrete(name = \"Fish Species\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  coord_flip() +\n  scale_fill_brewer(palette = \"Paired\")\n\n# Get all company names excluding the first 50 alphabetically\ncompanies2 <- distinct_species %>%\n  distinct(vessel_company) %>%\n  arrange(vessel_company) %>%\n  slice(51:n()) %>%\n  pull(vessel_company)\n\n# Filter the main dataframe to include only these companies\ncompanies2_data <- distinct_species %>%\n  filter(vessel_company %in% companies2)\n\n# Creating stacked bar chart\np2 <- ggplot(companies2_data, aes(x = vessel_company, fill = fish_species)) +\n  geom_bar(position = \"stack\") +\n  labs(title = \"Probable Fish Species Delivered by Company\",\n       x = \"Vessel Company\",\n       y = \"Fish Species\") +\n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_text(size = 8),\n        legend.text = element_text(size = 8),\n        legend.title = element_text(size = 8)) +\n  scale_fill_discrete(name = \"Fish Species\") +\n  coord_flip() +\n  scale_fill_brewer(palette = \"Paired\")\n\np2\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1\n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n::: {style=\"border: 2px dotted black; background-color: #caf0f8; padding: 15px; margin: 10px 0; border-radius: 5px; display: flex; align-items: center;\"}\n<img src=\"shark_4864506.png\" alt=\"Icon\" style=\"width: 48px; height: 48px; margin-right: 10px;\"/> **Observation:** It is observed that SouthSeafood Express Corp's catch content has fewer types of fish species comparing to rest of the companies which catch at least 8-9 species. SouthSeafood Express Corp's catch content shows 5 species of fish namely: Wrasse, Sockfish, Harland, Cod and Beauvoir. It is abnormal that SouthSeafood Express Corp is the only company with lowest number of fish species in the catch content while other companies catch at least 8-9 species. This observation calls for further deep dive in catch content and delivery document of SouthSeafood Express Corp since low catch content may indicate under-declaring the actual catch from fishing to officials.\n:::\n\n### 3.1.2 Seasonal Trend in Delivery Content\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert deliver_date to a date format and extract year-month\nN_Delivery_doc <- N_Delivery_doc %>%\n  mutate(year_month = floor_date(deliver_date, \"month\"))\n\n# Aggregate data by year-month\nmonthly_data <- N_Delivery_doc %>%\n  group_by(year_month) %>%\n  summarise(total_qty_tons = sum(qty_tons))\n\n# Extract the month from the 'date' column\nmonthly_data$month <- format(monthly_data$year_month, \"%B\")\n\n# Plot the data\nggplot(monthly_data, aes(x = year_month, y = total_qty_tons)) +\n  geom_bar(stat = \"identity\", fill = \"plum4\") +\n  labs(title = \"Total Quantity of Fish Fished per Month\",\n       x = \"Month\",\n       y = \"Total Quantity (tons)\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))+\n  scale_x_continuous(breaks = monthly_data$year_month) \n```\n\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## 3.2 Visualisations for Question 2\n\n### 3.2.1 Vessel Movement\n\nTransponder ping data can provide the locations the vessels from shipping company has been to and give insight whether vessels have visited non-fishing areas. In this section, we will focus only on fishing vessels to understand fishing activities.\n\nZoom into SouthSeafood Express Corp's vessel movement to uncover any suspicious behavior.\n\n::: panel-tabset\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter SouthSeafood Express Corp Vessels Only\nE_Tping_Fishing_SS <- E_Tping_Fishing %>%\n  filter(vessel_company == \"SouthSeafood Express Corp\")\n\nedges_ss <- data.frame(\n  from = E_Tping_Fishing_SS$vessel_company,\n  to = E_Tping_Fishing_SS$source\n)\n\n# Creating graph object\ngraph_ss <- graph_from_data_frame(edges_ss, directed = FALSE)\n\n\n# Distinguish between SouthSeafood and location\nV(graph_ss)$type <- ifelse(V(graph_ss)$name == \"SouthSeafood Express Corp\", \"southseafood\", \n                        ifelse(V(graph_ss)$name %in% E_Tping_Fishing_SS$vessel_id, \"boat\", \"location\"))\n\n# Plot the network with ggraph\nggraph(graph_ss, layout = 'fr') +  \n  geom_edge_link(aes(width = 1), edge_colour = \"grey\") + \n  geom_node_point(aes(color = type), size = 5) + \n  geom_node_text(aes(label = name), repel = TRUE, size = 3, color = \"black\") +  \n  scale_color_manual(values = c(\"boat\" = \"orange\", \"location\" = \"plum\", \"southseafood\" = \"maroon3\")) + \n  theme_void() +  \n  labs(title = \"Network Visualization of SouthSeafood Express Corp Vessel Movement\")  \n```\n:::\n\n:::\n\n\n::: {style=\"border: 2px dotted black; background-color: #caf0f8; padding: 15px; margin: 10px 0; border-radius: 5px; display: flex; align-items: center;\"}\n<img src=\"ship_1826384.png\" alt=\"Icon\" style=\"width: 48px; height: 48px; margin-right: 10px;\"/> **Observation:** One anomaly noted here is that SouthSeafood Express Corp Vessels visited [Ghoti Preserve]{.underline} which is not a fishing ground but ecological reserve.\n:::\n\nCreating vessel movement data table based in transponder ping and adding corresponding co-oridinates to data for further visualisation.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create vessel movement data table\nvessel_movement_data <- E_TransponderPing %>%\n    select(time, dwell, source, vessel_id)\n\n# Tidy source column\nvessel_movement_data <- vessel_movement_data%>%\n  mutate(source = gsub(\"^City of\", \"\", source)) %>%\n  mutate(source = gsub(\"^\\\\s+\", \"\", source))\n\n# Add X, Y coordinates to vessel movement data table\ncoords <- st_coordinates(OceanusLocations)\n\nOceanusLocations_df <- OceanusLocations %>%\n  st_drop_geometry()\n\nOceanusLocations_df$XCOORD <- coords[, \"X\"]\nOceanusLocations_df$YCOORD <- coords[, \"Y\"]\n\nOceanusLocations_df <- OceanusLocations_df %>%\n  select(Name, X.Kind, XCOORD, YCOORD) %>%\n  rename(Loc_Type = X.Kind)\n\nvessel_movement_data <- vessel_movement_data %>%\n  left_join(OceanusLocations_df,\n            by = c(\"source\" = \"Name\"))\n\n# save data as rds format\nwrite_rds(vessel_movement_data, \"data/rds/vessel_movement_data.rds\")\n```\n:::\n\n\n\nBelow code is used to create Vessel Trajectory Data.\n\n::: {.cell}\n\n```{.r .cell-code}\nvessel_movement_sf <- vessel_movement_data %>%\n  st_as_sf(coords = c(\"XCOORD\", \"YCOORD\"), \n           crs = 4326)\n\nvessel_movement_sf <- vessel_movement_sf %>%\n  arrange(vessel_id, time)\n\nvessel_trajectory <- vessel_movement_sf %>%\n  group_by(vessel_id) %>%\n  summarize(do_union = FALSE) %>%\n  st_cast(\"LINESTRING\")\n```\n:::\n\nBelow visualization shows Geo-Temporal Patterns of the SouthSeafood Express Corp Vessels.\n\n::: panel-tabset\n## snappersnatcher7be\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n## roachrobberdb6\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex03_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## Code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### snappersnatcher7be\nvessel_trajectory_selected1 <- vessel_trajectory %>%\n  filter(vessel_id == \"snappersnatcher7be\")\n\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf(data = vessel_trajectory_selected1, \n          aes(color = factor(vessel_id)), \n          size = 1) +\n  geom_text(data = OceanusLocations_df, \n            aes(x = XCOORD, y = YCOORD, label = Name), \n            size = 3, hjust = 1, vjust = 1) +\n  theme_minimal() +\n  labs(title = \"Trajectories of snappersnatcher7be\", \n  x = \"Longitude\", y = \"Latitude\", color = \"ID\")\n\n### roachrobberdb6\nvessel_trajectory_selected2 <- vessel_trajectory %>%\n  filter(vessel_id == \"roachrobberdb6\")\n\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf(data = vessel_trajectory_selected2, \n          aes(color = factor(vessel_id)), \n          size = 1) +\n  geom_text(data = OceanusLocations_df, \n            aes(x = XCOORD, y = YCOORD, label = Name), \n            size = 3, hjust = 1, vjust = 1) +\n  theme_minimal() +\n  labs(title = \"Trajectories of snappersnatcher7be\", \n  x = \"Longitude\", y = \"Latitude\", color = \"ID\")\n```\n:::\n\n:::\n\n### 3.2.2 Catch Content Deep Dive\n\n# 4. Conclusion\n\n# 5. References\n\n[Working with Graph Data](https://isss608-ay2023-24apr.netlify.app/vast/kickstarter2)\n\n[Working with Geographical Data](https://isss608-ay2023-24apr.netlify.app/vast/kickstarter3)\n\n[Icons used](https://www.freepik.com/)\n",
    "supporting": [
      "Take-home_Ex03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}